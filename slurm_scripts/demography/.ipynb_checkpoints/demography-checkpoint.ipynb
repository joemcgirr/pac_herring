{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import moments\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sbatch_header(job,mem,tasks,hours):\n",
    "    #sbatch submission script header\n",
    "    script = 'script_' + job + '.sh'\n",
    "    outfile = io.open(script,'w', newline='\\n')    \n",
    "    outfile.write('#!/bin/bash\\n\\n#SBATCH --job-name='+job+'\\n')\n",
    "    outfile.write('#SBATCH --mem='+mem+'G \\n')\n",
    "    outfile.write('#SBATCH --ntasks='+tasks+' \\n')\n",
    "    outfile.write('#SBATCH -e '+job+'_%A_%a.err \\n')\n",
    "    outfile.write('#SBATCH --time='+hours+':00:00  \\n')\n",
    "    outfile.write('#SBATCH --mail-user=jamcgirr@ucdavis.edu ##email you when job starts,ends,etc\\n#SBATCH --mail-type=ALL\\n')\n",
    "    outfile.write('#SBATCH -p high \\n\\n')\n",
    "    outfile.close()\n",
    "    \n",
    "def sbatch_header_loop(job,mem,tasks,hours,infile):\n",
    "    #sbatch submission script header\n",
    "    script = 'script_' + infile + job + '.sh'\n",
    "    outfile = io.open(script,'w', newline='\\n') \n",
    "    jobname= infile + job   \n",
    "    outfile.write('#!/bin/bash\\n\\n#SBATCH --job-name='+jobname+'\\n')\n",
    "    outfile.write('#SBATCH --mem='+mem+'G \\n')\n",
    "    outfile.write('#SBATCH --ntasks='+tasks+' \\n')\n",
    "    outfile.write('#SBATCH -e '+jobname+'_%A_%a.err \\n')\n",
    "    outfile.write('#SBATCH --time='+hours+':00:00 \\n')\n",
    "    outfile.write('#SBATCH --mail-user=jamcgirr@ucdavis.edu ##email you when job starts,ends,etc\\n#SBATCH --mail-type=ALL\\n')\n",
    "    outfile.write('#SBATCH -p high \\n\\n')\n",
    "    outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. LD prune master vcf\n",
    "\n",
    "job_name = 'LD_prune'\n",
    "vcf_name = 'ph_filtered_snps_minDP600_maxDP2000_maf0.05_minQ20_minMQ30_maxmiss0.5'\n",
    "\n",
    "sbatch_header(job_name,'8','8','24')\n",
    "script = 'script_' + job_name + '.sh'\n",
    "o = io.open(script,'a+', newline='\\n')\n",
    "\n",
    "\n",
    "o.write('module load plink \\n')\n",
    "o.write('plink --file /home/jamcgirr/ph/data/vcfs/'+vcf_name+'_outliers_rm --indep-pairwise 500 50 0.1 --out /home/jamcgirr/ph/data/angsd/SFS/downsample/ld_prune/'+vcf_name+'_500_50_0.1 --threads 8 \\n') \n",
    "o.write('sed \\'s/:/\\t/g\\' /home/jamcgirr/ph/data/angsd/SFS/downsample/ld_prune/'+vcf_name+'_500_50_0.1.prune.in > /home/jamcgirr/ph/data/angsd/SFS/downsample/ld_prune/ld_pruned_keep.txt \\n')\n",
    "o.write('/home/jamcgirr/apps/angsd_sep_20/angsd/angsd sites index /home/jamcgirr/ph/data/angsd/SFS/downsample/ld_prune/ld_pruned_keep.txt \\n')\n",
    "\n",
    "#run sbatch submission \n",
    "o.write('\\n\\n#command to run: sbatch '+script)\n",
    "o.close()\n",
    "\n",
    "# 2 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. subset populations and create saf\n",
    "\n",
    "job_name = '_subset_pops_pruned'\n",
    "\n",
    "saf_dir = '/home/jamcgirr/ph/data/moments/ld_prune/saf/'\n",
    "sfs_dir = '/home/jamcgirr/ph/data/moments/ld_prune/sfs/'\n",
    "vcf_name = 'ph_filtered_snps_minDP600_maxDP2000_maf0.05_minQ20_minMQ30_maxmiss0.5'\n",
    "infiles = [\"BC17\",\"CA17\",\"PWS07\",\"PWS17\",\"PWS91\",\"PWS96\",\"SS06\",\"SS17\",\"SS96\",\"TB06\",\"TB17\",\"TB91\",\"TB96\",\"WA17\"]\n",
    "\n",
    "for infile in infiles:\n",
    "    script = 'script_' + infile + job_name + '.sh'\n",
    "    sbatch_header_loop(job_name,'8','4','24', infile)\n",
    "    o = io.open(script,'a+', newline='\\n')\n",
    "        \n",
    "    o.write('#module load samtools \\n')\n",
    "    o.write('#module load bcftools \\n')\n",
    "\n",
    "    # subset master vcf \n",
    "    o.write('#bcftools view -S /home/jamcgirr/ph/scripts/angsd/SFS/SFS_by_pop/'+infile+'_plates_1_through_5_rm.txt -Ov /home/jamcgirr/ph/data/vcfs/vince/'+vcf_name+'_outliers_rm.vcf.gz -R /home/jamcgirr/ph/data/moments/ld_prune/pruned_keep.txt --threads 4 > /home/jamcgirr/ph/data/moments/ld_prune/vcfs/'+infile+'_pruned.vcf \\n')\n",
    "    # make saf from vcf\n",
    "    o.write('/home/jamcgirr/apps/angsd_sep_20/angsd/angsd -doSaf 1 -vcf-pl /home/jamcgirr/ph/data/moments/ld_prune/vcfs/'+infile+'_pruned.vcf -out /home/jamcgirr/ph/data/moments/ld_prune/saf/'+infile+' -anc /home/jamcgirr/ph/data/c_harengus/c.harengus.fa \\n\\n')\n",
    "    \n",
    "    # make folded sfs\n",
    "    o.write('/home/jamcgirr/apps/angsd_sep_20/angsd/misc/realSFS '+saf_dir+infile+'.saf.idx -fold 1 > '+sfs_dir+infile+'_folded.sfs \\n')\n",
    "    # make unfolded sfs\n",
    "    o.write('/home/jamcgirr/apps/angsd_sep_20/angsd/misc/realSFS '+saf_dir+infile+'.saf.idx > '+sfs_dir+infile+'_unfolded.sfs \\n')\n",
    "\n",
    "    #run sbatch submission \n",
    "    o.write('\\n\\n#command to run: sbatch '+script)\n",
    "    o.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create 2d sfs in dadi/moments format\n",
    "\n",
    "job_name = '_dadi_2d_sfs'\n",
    "\n",
    "realSFS = '/home/jamcgirr/apps/angsd/misc/realSFS'\n",
    "saf_dir = '/home/jamcgirr/ph/data/moments/ld_prune/saf/'\n",
    "sfs_dir = '/home/jamcgirr/ph/data/moments/ld_prune/sfs/'\n",
    "\n",
    "pop_n = {\"BC17\":\"64\",\"CA17\":\"70\",\"PWS07\":\"46\",\"PWS17\":\"56\",\"PWS91\":\"58\",\"PWS96\":\"72\",\"SS06\":\"41\",\"SS17\":\"64\",\"SS96\":\"78\",\"TB06\":\"52\",\"TB17\":\"72\",\"TB91\":\"74\",\"TB96\":\"73\",\"WA17\":\"72\"}\n",
    "infiles = [\"BC17_CA17\",\"BC17_WA17\",\"PWS07_PWS17\",\"PWS07_SS06\",\"PWS17_BC17\",\"PWS17_CA17\",\"PWS17_SS17\",\"PWS17_WA17\",\"PWS91_PWS07\",\"PWS91_PWS17\",\"PWS91_PWS96\",\"PWS96_PWS07\",\"PWS96_PWS17\",\"PWS96_SS96\",\"SS06_SS17\",\"SS17_BC17\",\"SS17_CA17\",\"SS17_WA17\",\"SS96_SS06\",\"SS96_SS17\",\"TB06_PWS07\",\"TB06_SS06\",\"TB06_TB17\",\"TB17_BC17\",\"TB17_CA17\",\"TB17_PWS17\",\"TB17_SS17\",\"TB17_WA17\",\"TB91_TB06\",\"TB91_TB17\",\"TB91_TB96\",\"TB96_PWS96\",\"TB96_SS96\",\"TB96_TB06\",\"TB96_TB17\",\"WA17_CA17\"]\n",
    "\n",
    "for infile in infiles:\n",
    "    script = 'script_' + infile + job_name + '.sh'\n",
    "    sbatch_header_loop(job_name,'16','4','24', infile)\n",
    "    o = io.open(script,'a+', newline='\\n')\n",
    "    \n",
    "    pops = ''.join(infile).split(\"_\")\n",
    "    \n",
    "    o.write('module load perl \\n')\n",
    "    \n",
    "    # folded\n",
    "    o.write(realSFS+' dadi '+saf_dir+pops[0]+'.saf.idx '+saf_dir+pops[1]+'.saf.idx -sfs '+sfs_dir+pops[0]+'_folded.sfs -sfs '+sfs_dir+pops[1]+'_folded.sfs -P 4 -ref /home/jamcgirr/ph/data/c_harengus/c.harengus.fa -anc /home/jamcgirr/ph/data/c_harengus/c.harengus.fa > /home/jamcgirr/ph/data/moments/2d_sfs_dadi/folded/'+pops[0]+'_'+pops[1]+'_dadi.sfs \\n')\n",
    "    o.write('/home/jamcgirr/apps/moments/AFS-analysis-with-moments/multimodel_inference/realsfs2dadi.pl /home/jamcgirr/ph/data/moments/2d_sfs_dadi/folded/'+pops[0]+'_'+pops[1]+'_dadi.sfs '+pop_n[pops[0]]+' '+pop_n[pops[1]]+' > /home/jamcgirr/ph/data/moments/2d_sfs_dadi/folded/'+pops[0]+'_'+pops[1]+'_dadi_snp.data \\n')\n",
    "    o.write('rm /home/jamcgirr/ph/data/moments/2d_sfs_dadi/folded/'+pops[0]+'_'+pops[1]+'_dadi.sfs \\n\\n')\n",
    "\n",
    "    # unfolded\n",
    "    o.write(realSFS+' dadi '+saf_dir+pops[0]+'.saf.idx '+saf_dir+pops[1]+'.saf.idx -sfs '+sfs_dir+pops[0]+'_unfolded.sfs -sfs '+sfs_dir+pops[1]+'_unfolded.sfs -P 4 -ref /home/jamcgirr/ph/data/c_harengus/c.harengus.fa -anc /home/jamcgirr/ph/data/c_harengus/c.harengus.fa > /home/jamcgirr/ph/data/moments/2d_sfs_dadi/unfolded/'+pops[0]+'_'+pops[1]+'_dadi.sfs \\n')\n",
    "    o.write('/home/jamcgirr/apps/moments/AFS-analysis-with-moments/multimodel_inference/realsfs2dadi.pl /home/jamcgirr/ph/data/moments/2d_sfs_dadi/unfolded/'+pops[0]+'_'+pops[1]+'_dadi.sfs '+pop_n[pops[0]]+' '+pop_n[pops[1]]+' > /home/jamcgirr/ph/data/moments/2d_sfs_dadi/unfolded/'+pops[0]+'_'+pops[1]+'_dadi_snp.data \\n')\n",
    "    o.write('rm /home/jamcgirr/ph/data/moments/2d_sfs_dadi/unfolded/'+pops[0]+'_'+pops[1]+'_dadi.sfs \\n\\n')\n",
    "\n",
    "\n",
    "    #run sbatch submission \n",
    "    o.write('\\n\\n#command to run: sbatch '+script)\n",
    "    o.close()\n",
    "    \n",
    "# sed -i 's/pop0/SS17/g' test_snps.txt\n",
    "# sed -i 's/pop1/BC17/g' test_snps.txt\n",
    "# sed -i 's/REF/Ingroup/g' test_snps.txt\n",
    "# sed -i 's/OUT/Outgroup/g' test_snps.txt\n",
    "\n",
    "    \n",
    "# 5 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot 2d sfs\n",
    "infiles = [\"BC17_CA17\",\"PWS17_CA17\",\"PWS91_PWS96\",\"TB17_PWS17\",\"TB91_TB96\"]\n",
    "\n",
    "for infile in infiles:\n",
    "    \n",
    "    pops = ''.join(infile).split(\"_\")\n",
    "    dadi_snps = \"C:/Users/jmcgirr/Documents/Whitehead_Lab/ph/moments/2d_sfs_dadi/pruned/unfolded/\" + pops[0] + \"_\" + pops[1] + \"_dadi_snp.data\"\n",
    "    dd = moments.Misc.make_data_dict(dadi_snps)\n",
    "    fs = moments.Spectrum.from_data_dict(dd,pop_ids=[ 'pop0' , 'pop1'],projections=[20 , 20],polarized = True)\n",
    "    #tfs = fs\n",
    "    #fs.mask[1, :] = True\n",
    "    #tfs.mask[1:5, :] = True\n",
    "    #tfs.mask[:, 1:5] = True\n",
    "    #S = fs.S()\n",
    "    #Fst = fs.Fst()\n",
    "    \n",
    "    moments.Plotting.plot_single_2d_sfs(fs, vmin =1)\n",
    "    fig_out = \"C:/Users/jmcgirr/Documents/Whitehead_Lab/ph/moments/2d_sfs_dadi/pruned/unfolded/figs/\" + pops[0] + \"_\" + pops[1] + \"_2d_sfs.png\"\n",
    "    plt.savefig(fig_out)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run moments pipeline\n",
    "model = '_sym_mig_2_pop'\n",
    "job_name = '_moments_pipeline'\n",
    "\n",
    "dadi_data_dir = '/home/jamcgirr/ph/data/moments/2d_sfs_dadi/folded/'\n",
    "#infiles = [\"BC17_CA17\",\"BC17_WA17\",\"PWS07_PWS17\",\"PWS07_SS06\",\"PWS17_BC17\",\"PWS17_CA17\",\"PWS17_SS17\",\"PWS17_WA17\",\"PWS91_PWS07\",\"PWS91_PWS17\",\"PWS91_PWS96\",\"PWS96_PWS07\",\"PWS96_PWS17\",\"PWS96_SS96\",\"SS06_SS17\",\"SS17_BC17\",\"SS17_CA17\",\"SS17_WA17\",\"SS96_SS06\",\"SS96_SS17\",\"TB06_PWS07\",\"TB06_SS06\",\"TB06_TB17\",\"TB17_BC17\",\"TB17_CA17\",\"TB17_PWS17\",\"TB17_SS17\",\"TB17_WA17\",\"TB91_TB06\",\"TB91_TB17\",\"TB91_TB96\",\"TB96_PWS96\",\"TB96_SS96\",\"TB96_TB06\",\"TB96_TB17\",\"WA17_CA17\"]\n",
    "infiles = [\"SS17_CA17\",\"PWS17_SS17\",\"TB17_SS17\",\"TB17_PWS17\"]\n",
    "\n",
    "for infile in infiles:\n",
    "    script = 'script_' + infile + job_name + '.sh'\n",
    "    sbatch_header_loop(job_name,'8','4','144', infile)\n",
    "    o = io.open(script,'a+', newline='\\n')\n",
    "    \n",
    "    pops = ''.join(infile).split(\"_\")\n",
    "\n",
    "    o.write('sed -i \\'s/pop0/'+pops[0]+'/g\\' '+dadi_data_dir+infile+'_dadi_snp.data \\n')\n",
    "    o.write('sed -i \\'s/pop1/'+pops[1]+'/g\\' '+dadi_data_dir+infile+'_dadi_snp.data \\n')\n",
    "    o.write('sed -i \\'s/REF/Ingroup/g\\' '+dadi_data_dir+infile+'_dadi_snp.data \\n')\n",
    "    o.write('sed -i \\'s/OUT/Outgroup/g\\' '+dadi_data_dir+infile+'_dadi_snp.data \\n')\n",
    "    \n",
    "    o.write('source /home/jamcgirr/apps/my_python3.7/bin/activate \\n')\n",
    "    o.write('python moments_Run_Optimizations.py \\n')\n",
    "    o.write('#python Simulate_and_Optimize.py \\n')\n",
    "    \n",
    "    o.write('\\n\\n#command to run: sbatch '+script)\n",
    "    o.close()\n",
    "    \n",
    "# 3 hrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "bottleneck() missing 2 required positional arguments: 'params' and 'ns'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-3a6cd10c1c49>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mfs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mbottleneck\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: bottleneck() missing 2 required positional arguments: 'params' and 'ns'"
     ]
    }
   ],
   "source": [
    "# simple bottleneck test\n",
    "\n",
    "def bottleneck(params, ns):\n",
    "    nuB , nuF , T = params\n",
    "    nu_func = lambda t: [ nuB * numpy . exp ( numpy. log( nuF/nuB )* t / T )]\n",
    "    sts = moments.LinearSystem_1D.steady_state_1D( ns [0])\n",
    "    fs = moments.Spectrum ( sts )\n",
    "    fs.integrate(nu_func , T )\n",
    "    return fs\n",
    "\n",
    "bottleneck()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = moments.Spectrum([88113,1222,132,445,285,176,41,20,73,276,192,68,50,23,3,2,47,50,0,0,362])\n",
    "\n",
    "sfs_file = 'C:/Users/jmcgirr/Desktop/population_CA17_minQ20_minMQ30_folded.sfs'\n",
    "\n",
    "with open(sfs_file) as data:\n",
    "    sfs = data.read().split()\n",
    "    sfs = sfs[math.ceil(((len(sfs)/2)*0.05)+2):]\n",
    "    sfs = [float(i) for i in sfs] \n",
    "    sfs = [round(num) for num in sfs]\n",
    "    sfs = [0] + sfs\n",
    "    fs = moments.Spectrum(sfs)\n",
    "    thetaW = fs.Watterson_theta()\n",
    "    print(thetaW)\n",
    "    #print(math.ceil(((len(sfs)/2)*0.05)+1))\n",
    "    nSites = sum(sfs[1:-1])\n",
    "    ne = thetaW / 2.0e-9 / nSites / 4\n",
    "    print(ne)\n",
    "    pi = fs.pi()\n",
    "    print(pi)\n",
    "    print(nSites)\n",
    "    print(pi/nSites)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-- 39199.1853634678 32166.59168577443 24975.560550045586\n",
      " 19527.14796354776 15059.660205318516 11984.49427442093 9913.224665350574\n",
      " 8687.263131828407 7969.7476527688605 7637.29510950767 7511.160547723575\n",
      " 7534.522808605096 7596.859841031881 7655.246724233557 3838.43843130088 --\n",
      " -- -- -- -- -- -- -- -- -- -- -- -- -- --]\n",
      "55663.26950289219\n",
      "0.1889978524331015\n"
     ]
    }
   ],
   "source": [
    "# create fs from vcf\n",
    "\n",
    "import moments\n",
    "\n",
    "#vcf_filename = \"/home/jamcgirr/ph/data/vcfs/chr1_ph_filtered_snps_minDP600_maxDP2000_maf0.05_minQ20_minMQ30_maxmiss0.5_outliers_rm.vcf\"\n",
    "#popinfo_filename = \"/home/jamcgirr/ph/scripts/easySFS/moments/popBCCA_file.txt\"\n",
    "#\n",
    "#dd = moments.Misc.make_data_dict_vcf(vcf_filename,popinfo_filename)\n",
    "#fs = Spectrum.from_data_dict (dd,polarized = True)\n",
    "\n",
    "filename = \"C:/Users/jmcgirr/Desktop/BC17_pruned.vcf.dadi\"\n",
    "dd = moments.Misc.make_data_dict(filename)\n",
    "fs = moments.Spectrum.from_data_dict (dd,pop_ids = [\"Pop1\"],projections = [30],polarized = False)\n",
    "print(fs)\n",
    "pi = fs.pi()\n",
    "print(pi)\n",
    "#nSites = sum(fs[1:-1])\n",
    "print(pi/294518)\n",
    "#fs.to_file(\"C:/Users/jmcgirr/Desktop/BC17_dadi.sfs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use downsampled 41 saf\n",
    "\n",
    "job_name = '_ld_pruned_downsample_sfs'\n",
    "saf_dir = \"/home/jamcgirr/ph/data/angsd/SFS/downsample/saf/\"\n",
    "\n",
    "infiles = [\"BC17\",\"CA17\",\"PWS07\",\"PWS17\",\"PWS91\",\"PWS96\",\"SS06\",\"SS17\",\"SS96\",\"TB06\",\"TB17\",\"TB91\",\"TB96\",\"WA17\"]\n",
    "#infiles = [\"BC17\"]\n",
    "\n",
    "for infile in infiles:\n",
    "    script = 'script_' + infile + job_name + '.sh'\n",
    "    sbatch_header_loop(job_name,'40','8','24', infile)\n",
    "    o = io.open(script,'a+', newline='\\n')\n",
    "    \n",
    "    \n",
    "    # make folded sfs\n",
    "    o.write('/home/jamcgirr/apps/angsd_sep_20/angsd/misc/realSFS '+saf_dir+infile+'_minQ20_minMQ30.saf.idx -P 8 -fold 1 -nSites 100000000 -sites /home/jamcgirr/ph/data/angsd/SFS/downsample/ld_prune/ld_pruned_keep.txt > /home/jamcgirr/ph/data/angsd/SFS/downsample/ld_prune/'+infile+'_minQ20_minMQ30_folded_ld_pruned.sfs \\n')\n",
    "\n",
    "    o.write('\\n\\n#run: sbatch '+script)\n",
    "    o.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# starting from 2021 vcf that fixed filtering issue\n",
    "# new solution to deal with singletons and doubletons\n",
    "# filter vcf (no maf filter) to include sites with high coverage and \n",
    "# little missing data\n",
    "#\n",
    "# from fantastic beasts:\n",
    "# there is a concern that high variation in coverage across samples and populations might\n",
    "# affect ANGSD statistics; to avoid this potential issue it is recommended to discard the lowest\n",
    "# coverage outliers and down-sample reads from highest-coverage outliers (J. Ross-Ibarra, pers.comm.). \n",
    "\n",
    "\n",
    "job_name = 'LD'\n",
    "vcf_name = 'ph_filtered_snps_minDP600_maxDP2000_minQ20_minMQ30_NS0.5'\n",
    "\n",
    "sbatch_header(job_name,'30','8','24')\n",
    "script = 'script_' + job_name + '.sh'\n",
    "o = io.open(script,'a+', newline='\\n')\n",
    "\n",
    "\n",
    "o.write('module load plink \\n')\n",
    "o.write('plink --file /home/jamcgirr/ph/data/vcfs/'+vcf_name+' --indep-pairwise 500 50 0.1 --r2 --out /home/jamcgirr/ph/data/plink/'+vcf_name+'_indep_pairwise_500_50_0.1 --threads 8 \\n') \n",
    "o.write('#sed \\'s/:/\\t/g\\' /home/jamcgirr/ph/data/plink/'+vcf_name+'_indep_pairwise_500_50_0.1.prune.in > /home/jamcgirr/ph/data/plink/'+vcf_name+'_indep_pairwise_500_50_0.1.prune.in.tab \\n')\n",
    "\n",
    "#run sbatch submission \n",
    "o.write('\\n\\n#command to run: sbatch '+script)\n",
    "o.close()\n",
    "\n",
    "\n",
    "\n",
    "job_name = 'filter_vcf_for_moments'\n",
    "vcf_name = 'ph_filtered_snps_minDP600_maxDP2000_minQ20_minMQ30_NS0.5'\n",
    "\n",
    "sbatch_header(job_name,'8','8','24')\n",
    "script = 'script_' + job_name + '.sh'\n",
    "o = io.open(script,'a+', newline='\\n')\n",
    "\n",
    "o.write('module load bcftools \\n')\n",
    "o.write('bcftools view -R /home/jamcgirr/ph/data/plink/'+vcf_name+'_indep_pairwise_500_50_0.1.prune.in.tab /home/jamcgirr/ph/vcfs/'+vcf_name+'.vcf.gz -Oz > /home/jamcgirr/ph/moments/vcfs/'+vcf_name+'_ld0.1.vcf.gz \\n')\n",
    "o.write('bcftools query --threads 8 -f \\'%CHROM %POS %DP %NS\\\\n\\' /home/jamcgirr/ph/moments/vcfs/'+vcf_name+'_ld0.1.vcf.gz > /home/jamcgirr/ph/moments/vcfs/'+vcf_name+'_ld0.1.DP.NS.info \\n')\n",
    "# 90% genotyping rate NS > 802 removes all sites\n",
    "# use strict depth filter instead\n",
    "o.write('#bcftools filter -Oz --threads 4 -i \\'INFO/DP>1300\\' /home/jamcgirr/ph/data/vcfs/'+vcf_name+'.vcf.gz -o /home/jamcgirr/ph/data/moments/vcfs/ph_filtered_snps_minDP1300_maxDP2000_minQ20_minMQ30_NS0.5.vcf.gz \\n\\n')\n",
    "# output depth at all sites\n",
    "\n",
    "\n",
    "#run sbatch submission \n",
    "o.write('\\n\\n#command to run: sbatch '+script)\n",
    "o.close()\n",
    "\n",
    "# ~ 1 hr\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
