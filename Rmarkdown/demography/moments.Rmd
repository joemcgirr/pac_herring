---
title: "moments"
author: "Joe McGirr"
date: "9/23/2020"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(tidyverse)
library(reticulate)
library(reshape2)
library(plyranges)
library(seqinr)
#BiocManager::install("reticulate")

# install moments for reticulate compatilbility
# py_install("git+https://bitbucket.org/simongravel/moments.git", pip = TRUE)
# py_install("matplotlib", pip = TRUE)



# color-blind friendly 
# Wong, B. Points of view: Color blindness. Nat Methods (2011).
bla <- "#000000"
blu <- "#0072b2"
grb <- "#56b4e9"
lir <- "#cc79a7"
gre <- "#009e73"
red <- "#d55e00"
org <- "#e69f00"
yel <- "#f0e442"
gry<-  '#BBBBBB'

```


# 1D SFS stats
```{python, echo = FALSE}
#,results='hide'}

import moments
import math
fs = moments.Spectrum([88113,1222,132,445,285,176,41,20,73,276,192,68,50,23,3,2,47,50,0,0,362])

sfs_file = 'C:/Users/jmcgirr/Documents/Whitehead_Lab/ph/moments/ld_pruned/sfs/SS17_folded.sfs'

with open(sfs_file) as data:
    sfs = data.read().split()
    sfs = sfs[math.ceil(((len(sfs)/2)*0.05)+2):]
    sfs = [float(i) for i in sfs] 
    sfs = [round(num) for num in sfs]
    sfs = [0] + sfs
    fs = moments.Spectrum(sfs)
    fs.mask[1:3]=True
    print(fs)
    thetaW = fs.Watterson_theta()
    print(thetaW)
    #print(math.ceil(((len(sfs)/2)*0.05)+1))
    nSites = sum(sfs[1:-1])
    ne = thetaW / 2.0e-9 / nSites / 4
    print(ne)
    pi = fs.pi()
    print(pi)
    print(nSites)
    print(pi/nSites)

#f = open("C:/Users/jmcgirr/Documents/Whitehead_Lab/ph/angsd/SFS/unfolded/population_PWS91_ph_filtered_snps_minDP600_maxDP2000_maf0.05_minQ20_minMQ30_maxmiss0.5.sfs", "r")
#print(f)
#from numpy import loadtxt
#lines = loadtxt("filename.dat", comments="#", delimiter=",", unpack=False)
#lines = text_file.read("C:/Users/jmcgirr/Documents/Whitehead_Lab/ph/angsd/SFS/unfolded/population_PWS91_ph_filtered_snps_minDP600_maxDP2000_maf0.05_minQ20_minMQ30_maxmiss0.5.sfs").split(' ')
#D = fs . Tajima_D ()
#pi = fs.pi()
#thetaW = fs.Watterson_theta()

```

```{python, echo = FALSE}

import moments
import math
import pylab

sfs_file = 'C:/Users/jmcgirr/Documents/Whitehead_Lab/ph/moments/ld_pruned/sfs/CA17_folded.sfs'
sfs_file = 'C:/Users/jmcgirr/Documents/Whitehead_Lab/ph/angsd/SFS/folded/population_CA17_ph_filtered_snps_minDP600_maxDP2000_maf0.05_minQ20_minMQ30_maxmiss0.5.sfs'


with open(sfs_file) as data:
    sfs = data.read().split()
    sfs = sfs[math.ceil(((len(sfs)/2)*0.05)+2):]
    sfs = [float(i) for i in sfs] 
    sfs = [round(num) for num in sfs]
    sfs = [0] + sfs
    fs = moments.Spectrum(sfs)
    fs.mask[1:3]=True
    print(fs)
    #thetaW = fs.Watterson_theta()
    #print(thetaW)
    ##print(math.ceil(((len(sfs)/2)*0.05)+1))
    nSites = sum(sfs[1:-1])
    #ne = thetaW / 2.0e-9 / nSites / 4
    #print(ne)
    pi = fs.pi()
    print(pi)
    print(nSites)
    print(pi/nSites)
    #print(fs.sample_sizes[0])
    #n = 135
    #p = pylab.arange(0, n+1)/float(n)
    #print(p)
    #print(n / (n-1.0) * 2 * pylab.sum(fs * p*(1-p)))
    #print(pylab.sum(fs.data))
    #print(n / (n-1.0) * 2 * pylab.sum(fs * p*(1-p)) / pylab.sum(fs.data))
    
#
```



# Plot 1D SFS
```{r}
sfs<-(scan(  'C:/Users/jmcgirr/Documents/Whitehead_Lab/ph/angsd/SFS/folded/population_BC17_ph_filtered_snps_minDP600_maxDP2000_maf0.05_minQ20_minMQ30_maxmiss0.5.sfs'))
sfs<-(scan(  'C:/Users/jmcgirr/Documents/Whitehead_Lab/ph/moments/ld_pruned/sfs/SS17_folded.sfs'))

#png("C:/Users/jmcgirr/Desktop/Fig_3.png", height = 5, width = 8, units = 'in', res = 300)

barplot(sfs[-c(1,length(sfs))]) #plot variable sites 
abline(v=(((length(sfs)/2)*0.05)+1), col = "red")

#dev.off()

```

## 2D SFS stats and plot
```{python, echo = FALSE,results='hide'}

import moments
import matplotlib
dd = moments.Misc.make_data_dict('C:/Users/jmcgirr/Documents/Whitehead_Lab/ph/moments/2d_sfs_dadi/folded/BC17_CA17_dadi_snp.data')
fs = moments.Spectrum.from_data_dict(dd,pop_ids=[ 'pop0' , 'pop1'],projections=[30 , 30],polarized = True)
S = fs.S()
Fst = fs.Fst()
print(Fst)
#moments.Plotting.plot_single_2d_sfs(fs, vmin =1)
#matplotlib.pyplot.savefig("my_plot") 


```

## Run a simple model
one population split into two pops with symmetrical migration
```{r}

# http://evomics.org/wp-content/uploads/2016/01/dadi.pdf
# In dadi, all parameters are scaled by the effective size of the ancestral population. To find
# that effective size, we use the relationship θ = 4NeµL, where µ is the per-base mutation
# rate, and L is length of sequence from which the SNPs came. So Ne = θ/4µL. 

model_name <- "sym_mig_2_pop"
pops <- "PWS17_SS17"
pops <- "TB17_PWS17"


for (i in c(1:5)){
params <- read.delim(paste("C:/Users/jmcgirr/Documents/Whitehead_Lab/ph/moments/moments_pipeline/models/",model_name,"/",pops,"/V1_Number_",i,".sym_mig.optimized.txt", sep = ""))
params <- params[order(params$AIC),]
head(params)
params <- params %>% separate(Replicate, c("round","replicate"), remove = TRUE,sep = "_R")

print(boxplot(params$log.likelihood~params$round))
opt_params <- strsplit(params[1,8], ",")[[1]]
print("optimized parameter set for empirical data:")
print(opt_params)
print("theta")
print(params$theta[1])

}


best <- 3
  
params <- read.delim(paste("C:/Users/jmcgirr/Documents/Whitehead_Lab/ph/moments/moments_pipeline/models/",model_name,"/",pops,"/V3_Number_",best,".sym_mig.optimized.txt", sep = ""))
params <- params[order(params$AIC),]
params <- params %>% separate(Replicate, c("round","replicate"), remove = TRUE,sep = "_R")
#print(boxplot(params$log.likelihood~params$round))
opt_params <- strsplit(params[1,8], ",")[[1]]

   # Split into two populations, with symmetric migration.
   # nu1: Size of population 1 after split.
   # nu2: Size of population 2 after split.
   # m: Migration rate between populations (2*Na*m)
   # T: Time in the past of split (in units of 2*Na generations) 
   
theta <- as.numeric(params$theta[1])
nu1 <- as.numeric(opt_params[1])
nu2 <- as.numeric(opt_params[2])
m <- as.numeric(opt_params[3])
t <- as.numeric(opt_params[4])

# generation time
g <- 4
# atlantic herring mutation rate
mu <- 2.0e-9

#L <- 354549     # number of snps analyzed
L <- 25176157  # total length analyzed
# effective size of ancestral population
Nref <- theta / (4* mu* L)
Nref

# Time since split
t*2*Nref*4


################### Goodness of Fit
#Change the path to your output files, which will have names specific to the model you labeled
#These are for the example output files provided:

model_name <- "sym_mig_2_pop"
pops <- "PWS17_SS17"
pops <- "TB17_PWS17"


sim_data <- read.delim(paste("C:/Users/jmcgirr/Documents/Whitehead_Lab/ph/moments/moments_pipeline/models/",model_name,"/",pops,"/Simulation_Results.txt", sep = ""), header = TRUE, sep = "\t")
emp_data <- read.delim(paste("C:/Users/jmcgirr/Documents/Whitehead_Lab/ph/moments/moments_pipeline/models/",model_name,"/",pops,"/Empirical.sym_mig.optimized.txt", sep = ""), header = TRUE, sep = "\t")

#check headers
ls(sim_data)
#should be: Simulation	Best_Replicate	log-likelihood	theta	sfs_sum	chi-squared	optimized_params
ls(emp_data)
#should be: Model	Replicate	log-likelihood	theta	sfs_sum	chi-squared

#quick summary of files:
summary(sim_data)
summary(emp_data)

#summary of variables for simulated sfs fits:
summary(sim_data$log.likelihood)
summary(sim_data$chi.squared)

#summary of empirical values:
emp_data$log.likelihood
emp_data$chi.squared


#####################################
#FREQUENCY DISTRIBUTIONS
#Edit below numbers to change the frequency distribution set up for your data,
#by checking the summary functions above.

#syntax for setting bin number is: seq(low number, high number, increment)
#-----------------------------------------------------------------------------------------

#likelihood plot
#change the bin settings below
ll_seq<- seq(-100,-20,2)
hist(sim_data$log.likelihood, breaks=500, main = "Simulation Results - Log-likelihood distribution", xlab="log-likelihood", col="grey")
abline(v=emp_data$log.likelihood, lwd = 3, col='blue')

#chi-squared plot
#change the bin settings below
chi_seq<- seq(0,100,5)
hist(sim_data$chi.squared, breaks=100, main = "Simulation Results - Chi-squared distribution ", xlab="Chi-squared test statistic", col="grey")
abline(v=emp_data$chi.squared, lwd = 3, col='blue')

#####################################
#For log-transformed chi.squared

#transform chi-squared test stat
log_chi <- log(sim_data$chi.squared)
emp_log_chi <- log(emp_data$chi.squared)
summary(log_chi)


#log transformed chi-squared plot
#change the bin settings below
lchi_seq<- seq(0,8,0.2)
hist(log_chi, breaks=lchi_seq, main = "Simulation Results - Log Chi-squared distribution ", xlab="log Chi-squared test statistic", col="grey")
abline(v=emp_log_chi, lwd = 3, col='blue')

```





```{r, eval = FALSE}
# not trusting thetaW output

# Rough Ne estimate using waterson's theta

# http://evomics.org/learning/population-and-speciation-genomics/2018-population-and-speciation-genomics/angsd-activity-sfs-fst-pbs/

pop_names = c("PWS91","PWS96","PWS07","PWS17","TB91","TB96","TB06","TB17","SS96","SS06","SS17","BC17","WA17","CA17")
pop <- "PWS07"
ne_s <- c()
for (pop in pop_names){
x<-scan(paste("C:/Users/jmcgirr/Documents/Whitehead_Lab/ph/angsd/SFS/unfolded/population_",pop,"_ph_filtered_snps_minDP600_maxDP2000_maf0.05_minQ20_minMQ30_maxmiss0.5.sfs", sep = ""))

x <- x[c(round((((length(x)/2)*0.05)+2)):length(x))]

nSites<-sum(x)   #Number of sites where we have data
#nSeg<-sum(x[c(-1)])    #Number of segregating sites
nSeg <- nSites
an <- function(n) sum(1/1:(n-1))
thetaW <- nSeg/an(length(x[c(-1)])/2) # Wattersons Theta
#print(pop)
#print("effective population size")
ne <- thetaW / 2.0e-9 / nSites / 4 # effective population size
#print(ne)
ne_s <- c(ne_s, ne)
}

```











```{r,eval=FALSE}
#https://github.com/z0on/AFS-analysis-with-moments
#http://computationalgenomics.bioinformatics.ucla.edu/portfolio/simon-gravel-inferring-demographic-history-using-moments-cgsi-2019/

#https://bitbucket.org/simongravel/moments/src/master/moments/

#https://dadi.readthedocs.io/en/latest/user-guide/importing-data/

#https://github.com/isaacovercast/easySFS

#https://github.com/dportik/moments_pipeline

#https://notebook.community/claudiuskerth/PhDthesis/Data_analysis/SNP-indel-calling/dadi/dadiExercises/.ipynb_checkpoints/First_Steps_with_dadi-checkpoint


# autocorrelation and autocovariance
#https://www.ssc.wisc.edu/~bhansen/390/390Lecture7.pdf

# https://github.com/z0on/AFS-analysis-with-moments
# http://computationalgenomics.bioinformatics.ucla.edu/portfolio/simon-gravel-inferring-demographic-history-using-moments-cgsi-2019/

# https://bitbucket.org/simongravel/moments/src/master/moments/

# https://dadi.readthedocs.io/en/latest/user-guide/importing-data/

# https://github.com/isaacovercast/easySFS


#!/bin/bash

#SBATCH --job-name=moments_test
#SBATCH --mem=8G 
#SBATCH --ntasks=4 
#SBATCH -e moments_test_%A_%a.err 
#SBATCH --time=1:00:00 
#SBATCH --mail-user=jamcgirr@ucdavis.edu ##email you when job starts,ends,etc
#SBATCH --mail-type=ALL
#SBATCH -p high 

#/home/jamcgirr/apps/angsd_sep_20/angsd/angsd -bam p1.bams -doSaf 1 -anc /home/jamcgirr/ph/data/c_harengus/c.harengus.fa -GL 1 -P 8 -out p1 -minMapQ 1 -minQ 20 
#/home/jamcgirr/apps/angsd_sep_20/angsd/angsd -bam p2.bams -doSaf 1 -anc /home/jamcgirr/ph/data/c_harengus/c.harengus.fa -GL 1 -P 8 -out p2 -minMapQ 1 -minQ 20                                                                                                                                                       
 
#/home/jamcgirr/apps/angsd_sep_20/angsd/misc/realSFS p1.saf.idx p2.saf.idx -bootstrap 10 -P 4 -r chr1:1-100000 > p12_boots.sfs
/home/jamcgirr/apps/angsd_sep_20/angsd/misc/realSFS p1.saf.idx  -P 4 -r chr1:1-100000 > p1.sfs
/home/jamcgirr/apps/angsd_sep_20/angsd/misc/realSFS p2.saf.idx  -P 4 -r chr1:1-100000 > p2.sfs

#split -l 1 -d --additional-suffix=.sfs p12_boots.sfs p12_

# mv p12_00.sfs p12_10.sfs
# mv p12_01.sfs p12_1.sfs
# mv p12_02.sfs p12_2.sfs
# mv p12_03.sfs p12_3.sfs
# mv p12_04.sfs p12_4.sfs
# mv p12_05.sfs p12_5.sfs
# mv p12_06.sfs p12_6.sfs
# mv p12_07.sfs p12_7.sfs
# mv p12_08.sfs p12_8.sfs
# mv p12_09.sfs p12_9.sfs

module load R
Rscript /home/jamcgirr/apps/moments/AFS-analysis-with-moments/modSel_write.R contrast=p12 args="p1 p2 16 16 0.02 0.005"
source /home/jamcgirr/apps/my_python3.7/bin/activate

sleep 1 && /home/jamcgirr/apps/moments/AFS-analysis-with-moments/multimodel_inference/py3/IM.py p12_1.sfs p1 p2 16 16 0.02 0.005 >>p12.modsel

#/home/jamcgirr/apps/angsd_sep_20/angsd/misc/realSFS dadi p1.saf.idx p2.saf.idx -sfs p1.sfs -sfs p2.sfs -r chr1:1-100000 -ref /home/jamcgirr/ph/data/c_harengus/c.harengus.fa -anc /home/jamcgirr/ph/data/c_harengus/c.harengus.fa > dadiout
#
#/home/jamcgirr/apps/moments/AFS-analysis-with-moments/multimodel_inference/realsfs2dadi.pl dadiout 10 10 > 2pops_dadi.data
#
#/home/jamcgirr/apps/moments/AFS-analysis-with-moments/multimodel_inference/py3/2dAFS.py 2pops_dadi.data p1 p2 16 16


# get Fst for 2d SFS and plot SFS

python
import moments
dd = moments.Misc.make_data_dict('2pops_dadi.data')
fs = moments.Spectrum.from_data_dict(dd,pop_ids=[ 'pop0' , 'pop1'],projections=[16 , 16],polarized = True)
S = fs.S()
Fst = fs.Fst()
moments.Plotting.plot_single_2d_sfs(fs, vmin =1)
import matplotlib
matplotlib.pyplot.savefig("my_plot") 


# get pi and tajD for 1d SFS

python
import moments
dd = moments.Misc.make_data_dict('2pops_dadi.data')
#fs = moments.Spectrum([88113,1222,132,445,285,176,41,20,73,276,192,68,50,23,3,2,47,50,0,0,362])
D = fs . Tajima_D ()
pi = fs.pi()
thetaW = fs.Watterson_theta()

#command to run: sbatch script_moments_test.sh

```


